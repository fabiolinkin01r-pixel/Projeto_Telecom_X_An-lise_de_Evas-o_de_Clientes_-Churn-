{"cells":[{"cell_type":"markdown","id":"f217bdef","metadata":{"id":"f217bdef"},"source":["# Projeto Telecom X — Análise de Evasão de Clientes (Churn)\n","\n","**Autor original:** Paulo Henrique Santana Motta  \n","**Melhorias aplicadas:** Refatoração do fluxo ETL, funções reutilizáveis, feature engineering, pipeline de ML (Logistic Regression), avaliação robusta, visualizações aprimoradas e seção de conclusões.\n","\n","Este notebook foi gerado automaticamente para melhorar a estrutura e a reprodutibilidade do projeto.\n"]},{"cell_type":"markdown","id":"c23d7f80","metadata":{"id":"c23d7f80"},"source":["## Sumário\n","\n","1. Setup e imports\n","2. Carregamento dos dados\n","3. Funções utilitárias (ETL & Preprocessing)\n","4. Análise Exploratória (EDA)\n","5. Feature Engineering\n","6. Modelagem Preditiva (Pipeline)\n","7. Avaliação e Métricas\n","8. Insights e Conclusões\n","\n","---\n"]},{"cell_type":"code","execution_count":null,"id":"7bce969c","metadata":{"id":"7bce969c"},"outputs":[],"source":["# 1) Setup e imports\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n","                             roc_auc_score, confusion_matrix, classification_report, roc_curve, auc)\n","\n","pd.set_option('display.max_columns', 200)\n","pd.set_option('display.max_colwidth', 200)\n","\n","# Fonte dos dados (originalmente usado no projeto)\n","url = \"https://raw.githubusercontent.com/alura-cursos/challenge2-data-science/main/TelecomX_Data.json\"\n","print('Setup pronto. URL dos dados:', url)\n"]},{"cell_type":"code","execution_count":null,"id":"cdffb0cb","metadata":{"id":"cdffb0cb"},"outputs":[],"source":["# 2) Carregamento dos dados\n","\n","df = pd.read_json(url)\n","print('Dimensão do dataset:', df.shape)\n","df.head()\n"]},{"cell_type":"code","execution_count":null,"id":"0146449b","metadata":{"id":"0146449b"},"outputs":[],"source":["# 3) Funções utilitárias: limpeza, tratamento e feature engineering\n","\n","def quick_report(df):\n","    print('--- RESUMO ---')\n","    print('Linhas, colunas:', df.shape)\n","    print('\\nTipos de dados:')\n","    print(df.dtypes)\n","    print('\\nValores ausentes por coluna:')\n","    print(df.isnull().sum().sort_values(ascending=False).head(20))\n","\n","\n","def preprocess_basic(df):\n","    df = df.copy()\n","    # Remover duplicatas\n","    df = df.drop_duplicates()\n","\n","    # Converter colunas numéricas mal interpretadas\n","    # (aplica-se conforme existam strings em colunas numéricas)\n","    for col in df.select_dtypes(include=['object']).columns:\n","        # tentar converter para num quando for completamente numérico\n","        try:\n","            coerced = pd.to_numeric(df[col], errors='coerce')\n","            non_null_ratio = coerced.notnull().mean()\n","            if non_null_ratio > 0.95 and coerced.nunique() > 5:\n","                df[col] = coerced\n","        except Exception:\n","            pass\n","\n","    return df\n","\n","\n","def feature_engineer(df):\n","    df = df.copy()\n","    # Exemplo de features simples\n","    if 'MonthlyCharges' in df.columns and 'TotalCharges' in df.columns:\n","        df['avg_months'] = df['TotalCharges'] / (df['MonthlyCharges'].replace(0, np.nan))\n","        df['avg_months'] = df['avg_months'].fillna(0).replace([np.inf, -np.inf], 0)\n","    # Binarizar churn se ainda não estiver 0/1\n","    if 'Churn' in df.columns:\n","        df['Churn_flag'] = df['Churn'].map({'Yes':1, 'No':0}) if df['Churn'].dtype == object else df['Churn']\n","    return df\n","\n","print('Funções utilitárias definidas.')\n"]},{"cell_type":"code","execution_count":null,"id":"443a9d25","metadata":{"id":"443a9d25"},"outputs":[],"source":["# 4) Análise Exploratória Rápida (EDA)\n","\n","quick_report(df)\n","\n","# Distribuição da variável alvo (Churn)\n","if 'Churn' in df.columns:\n","    display(df['Churn'].value_counts(dropna=False))\n","\n","# Algumas visualizações rápidas\n","plt.figure(figsize=(6,4))\n","if 'Churn' in df.columns:\n","    df['Churn'].value_counts(normalize=True).plot(kind='bar')\n","    plt.title('Distribuição de Churn')\n","    plt.xlabel('Churn')\n","    plt.ylabel('Proporção')\n","    plt.show()\n","\n","# Correlação entre numéricas\n","num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n","if len(num_cols) > 1:\n","    corr = df[num_cols].corr()\n","    print('\\nTop 10 correlações com Churn_flag (se existir):')\n","    if 'Churn_flag' in df.columns:\n","        print(corr['Churn_flag'].abs().sort_values(ascending=False).head(10))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"c69ec351","metadata":{"id":"c69ec351"},"outputs":[],"source":["# 5) Aplicar pré-processamento e feature engineering\n","\n","df_clean = preprocess_basic(df)\n","df_fe = feature_engineer(df_clean)\n","print('Dimensão após FE:', df_fe.shape)\n","df_fe.head()\n"]},{"cell_type":"code","execution_count":null,"id":"158a01cf","metadata":{"id":"158a01cf"},"outputs":[],"source":["# 6) Modelagem preditiva — Pipeline simples (Logistic Regression)\n","\n","# Preparar X e y\n","if 'Churn_flag' not in df_fe.columns:\n","    raise ValueError('Coluna Churn_flag ausente — verifique o dataset e a etapa de feature engineering')\n","\n","y = df_fe['Churn_flag']\n","X = df_fe.drop(columns=['Churn', 'Churn_flag']) if 'Churn' in df_fe.columns else df_fe.drop(columns=['Churn_flag'])\n","\n","# Selecionar tipos\n","numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n","cat_features = X.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n","\n","print('Numérico:', len(numeric_features), 'Categórico:', len(cat_features))\n","\n","# Simple pipeline\n","numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n","cat_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n","\n","preprocessor = ColumnTransformer(transformers=[\n","    ('num', numeric_transformer, numeric_features),\n","    ('cat', cat_transformer, cat_features)\n","])\n","\n","clf = Pipeline(steps=[('preprocessor', preprocessor),\n","                      ('classifier', LogisticRegression(max_iter=1000))])\n","\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=42)\n","\n","# Treinar\n","clf.fit(X_train, y_train)\n","print('Treinamento concluído.')\n","\n","# Prever\n","y_pred = clf.predict(X_test)\n","y_proba = clf.predict_proba(X_test)[:,1]\n","\n","print('Acurácia (teste):', accuracy_score(y_test, y_pred))\n","print('\\nRelatório de classificação:\\n', classification_report(y_test, y_pred))\n","print('\\nROC-AUC:', roc_auc_score(y_test, y_proba))\n"]},{"cell_type":"code","execution_count":null,"id":"05bd03b3","metadata":{"id":"05bd03b3"},"outputs":[],"source":["# 7) Avaliação — Matriz de confusão e ROC\n","\n","# Matriz de confusão\n","cm = confusion_matrix(y_test, y_pred)\n","plt.figure(figsize=(5,4))\n","plt.imshow(cm, interpolation='nearest')\n","plt.title('Matriz de Confusão')\n","plt.xlabel('Predito')\n","plt.ylabel('Verdadeiro')\n","for i in range(cm.shape[0]):\n","    for j in range(cm.shape[1]):\n","        plt.text(j, i, cm[i, j], ha='center', va='center')\n","plt.colorbar()\n","plt.show()\n","\n","# Curva ROC\n","fpr, tpr, _ = roc_curve(y_test, y_proba)\n","roc_auc = auc(fpr, tpr)\n","plt.figure(figsize=(6,4))\n","plt.plot(fpr, tpr)\n","plt.plot([0,1],[0,1], linestyle='--')\n","plt.title('ROC Curve (AUC = {:.3f})'.format(roc_auc))\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.show()\n","\n","# Top features (apenas para coeficientes do modelo linear)\n","try:\n","    # extrair feature names do preprocessor\n","    ohe_cols = []\n","    if len(cat_features) > 0:\n","        ohe = clf.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']\n","        cat_names = list(ohe.get_feature_names_out(cat_features))\n","    else:\n","        cat_names = []\n","    feat_names = numeric_features + cat_names\n","    coefs = clf.named_steps['classifier'].coef_[0]\n","    feat_imp = pd.DataFrame({'feature': feat_names, 'coef': coefs})\n","    feat_imp['abs_coef'] = feat_imp['coef'].abs()\n","    feat_imp = feat_imp.sort_values('abs_coef', ascending=False).head(15)\n","    print('\\nTop features por importância (coef):')\n","    display(feat_imp)\n","except Exception as e:\n","    print('Não foi possível extrair importâncias automaticamente:', e)\n"]},{"cell_type":"markdown","id":"a0067efa","metadata":{"id":"a0067efa"},"source":["## 8) Insights e Conclusões\n","\n","- **Resumo da modelagem:** Implementamos um pipeline simples com pré-processamento (escalonamento + one-hot) e um classificador linear (Logistic Regression). Esta abordagem é rápida, interpretável e fornece baseline robusto.\n","- **Próximos passos recomendados:**\n","  - Balanceamento (SMOTE / undersampling) caso haja desbalanceamento forte.\n","  - Testar modelos mais complexos (RandomForest, XGBoost) e comparar via CV.\n","  - Ajustar features (feature selection, encoding target/ordinal quando aplicável).\n","  - Criar dashboard interativo (Plotly / Streamlit) para stakeholders.\n"]},{"cell_type":"code","execution_count":null,"id":"5aad578c","metadata":{"id":"5aad578c"},"outputs":[],"source":[]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}