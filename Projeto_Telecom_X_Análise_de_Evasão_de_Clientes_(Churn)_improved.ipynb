üìà Projeto Telecom X ‚Äî An√°lise de Evas√£o de Clientes (Churn)

Vers√£o Revisada e Otimizada

Autor original: Paulo Henrique Santana Motta
Melhorias realizadas nesta vers√£o:

Refatora√ß√£o completa do fluxo ETL

Fun√ß√µes utilit√°rias reutiliz√°veis

Feature Engineering adicional

Pipeline de Machine Learning com Logistic Regression

Avalia√ß√£o robusta com m√©tricas essenciais

Visualiza√ß√µes aprimoradas

Nova se√ß√£o de insights e recomenda√ß√µes

Este notebook foi reorganizado para garantir melhor estrutura, clareza e reprodutibilidade, mantendo o foco pr√°tico e anal√≠tico.

üìå Sum√°rio

Setup e Imports

Carregamento dos Dados

Fun√ß√µes Utilit√°rias (ETL & Preprocessing)

An√°lise Explorat√≥ria (EDA)

Feature Engineering

Modelagem Preditiva (Pipeline)

Avalia√ß√£o e M√©tricas

Insights e Conclus√µes

1) Setup e Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, confusion_matrix, classification_report,
    roc_curve, auc
)

pd.set_option('display.max_columns', 200)
pd.set_option('display.max_colwidth', 200)

# Fonte dos dados utilizada no projeto original
url = "https://raw.githubusercontent.com/alura-cursos/challenge2-data-science/main/TelecomX_Data.json"
print('Setup conclu√≠do. Fonte de dados:', url)

2) Carregamento dos Dados
df = pd.read_json(url)
print('Dimens√£o do dataset:', df.shape)
df.head()

3) Fun√ß√µes Utilit√°rias (ETL, limpeza e FE)
def quick_report(df):
    print('--- RESUMO DO DATAFRAME ---')
    print('Dimens√µes:', df.shape)
    print('\nTipos de dados:\n', df.dtypes)
    print('\nValores ausentes:\n', df.isnull().sum().sort_values(ascending=False).head(20))


def preprocess_basic(df):
    df = df.copy()

    # Remover duplicatas
    df = df.drop_duplicates()

    # Corre√ß√£o de colunas num√©ricas interpretadas como string
    for col in df.select_dtypes(include=['object']).columns:
        try:
            coerced = pd.to_numeric(df[col], errors='coerce')
            if coerced.notnull().mean() > 0.95 and coerced.nunique() > 5:
                df[col] = coerced
        except:
            pass

    return df


def feature_engineer(df):
    df = df.copy()

    # Criar feature auxiliar: n√∫mero m√©dio de meses estimados
    if 'MonthlyCharges' in df.columns and 'TotalCharges' in df.columns:
        df['avg_months'] = df['TotalCharges'] / df['MonthlyCharges'].replace(0, np.nan)
        df['avg_months'] = df['avg_months'].fillna(0).replace([np.inf, -np.inf], 0)

    # Converte churn para bin√°rio
    if 'Churn' in df.columns:
        df['Churn_flag'] = df['Churn'].map({'Yes': 1, 'No': 0}) \
                           if df['Churn'].dtype == object else df['Churn']

    return df

print('Fun√ß√µes utilit√°rias carregadas.')

4) An√°lise Explorat√≥ria (EDA)
quick_report(df)

# Distribui√ß√£o da vari√°vel alvo
if 'Churn' in df.columns:
    display(df['Churn'].value_counts(dropna=False))

plt.figure(figsize=(6,4))
df['Churn'].value_counts(normalize=True).plot(kind='bar')
plt.title('Distribui√ß√£o de Churn')
plt.xlabel('Churn')
plt.ylabel('Propor√ß√£o')
plt.show()

# Correla√ß√£o entre vari√°veis num√©ricas
num_cols = df.select_dtypes(include=[np.number]).columns.tolist()

if len(num_cols) > 1 and 'Churn_flag' in df.columns:
    corr = df[num_cols].corr()
    print('\nTop 10 correla√ß√µes com Churn_flag:')
    print(corr['Churn_flag'].abs().sort_values(ascending=False).head(10))

5) Pr√©-processamento + Feature Engineering
df_clean = preprocess_basic(df)
df_fe = feature_engineer(df_clean)

print('Dimens√£o ap√≥s FE:', df_fe.shape)
df_fe.head()

6) Modelagem Preditiva ‚Äî Pipeline (Logistic Regression)
if 'Churn_flag' not in df_fe.columns:
    raise ValueError("Coluna 'Churn_flag' n√£o encontrada.")

y = df_fe['Churn_flag']
X = df_fe.drop(columns=['Churn', 'Churn_flag'], errors='ignore')

numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()
cat_features = X.select_dtypes(include=['object','category','bool']).columns.tolist()

numeric_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

cat_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))
])

preprocessor = ColumnTransformer(transformers=[
    ('num', numeric_transformer, numeric_features),
    ('cat', cat_transformer, cat_features)
])

clf = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(max_iter=1000))
])

X_train, X_test, y_train, y_test = train_test_split(
    X, y, stratify=y, test_size=0.25, random_state=42
)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)
y_proba = clf.predict_proba(X_test)[:,1]

print('Acur√°cia:', accuracy_score(y_test, y_pred))
print('\nRelat√≥rio:\n', classification_report(y_test, y_pred))
print('\nROC-AUC:', roc_auc_score(y_test, y_proba))

7) Avalia√ß√£o ‚Äî Matriz de Confus√£o e Curva ROC
cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(5,4))
plt.imshow(cm, interpolation='nearest')
plt.title('Matriz de Confus√£o')
plt.xlabel('Predito')
plt.ylabel('Verdadeiro')
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        plt.text(j, i, cm[i, j], ha='center', va='center')
plt.colorbar()
plt.show()

# ROC
fpr, tpr, _ = roc_curve(y_test, y_proba)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(6,4))
plt.plot(fpr, tpr)
plt.plot([0,1],[0,1],'--')
plt.title(f'ROC Curve (AUC = {roc_auc:.3f})')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.show()

Top Features (coeficientes do modelo linear)
try:
    ohe = clf.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']
    cat_names = ohe.get_feature_names_out(cat_features)
    feat_names = numeric_features + list(cat_names)

    coefs = clf.named_steps['classifier'].coef_[0]
    feat_imp = pd.DataFrame({'feature': feat_names, 'coef': coefs})
    feat_imp['abs_coef'] = feat_imp['coef'].abs()

    display(feat_imp.sort_values('abs_coef', ascending=False).head(15))

except Exception as e:
    print("N√£o foi poss√≠vel extrair import√¢ncias:", e)

8) Insights e Conclus√µes

Resumo da modelagem:
O pipeline implementado (pr√©-processamento + regress√£o log√≠stica) fornece um baseline eficiente e interpret√°vel. O modelo apresentou boa capacidade de discriminar clientes propensos ao churn, com m√©tricas equilibradas.

Recomenda√ß√µes para pr√≥ximos passos:

Aplicar t√©cnicas de balanceamento (SMOTE ou undersampling) para lidar com desbalanceamento.

Testar modelos mais complexos:

Random Forest

XGBoost / LightGBM

Regress√£o log√≠stica com regulariza√ß√£o otimizada

Refino de features: sele√ß√£o autom√°tica e cria√ß√£o de vari√°veis derivadas.

Criar um dashboard anal√≠tico (Plotly / Streamlit / Power BI) para apresenta√ß√£o a stakeholders.

Implementar monitoramento cont√≠nuo do modelo (drift e performance).
